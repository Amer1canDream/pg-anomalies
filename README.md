# Поиск аномалий в работе PostgreSQL

## Постановка задачи

Цель - автоматически выявлять отклонения в работе PostgreSQL вне ручных порогов которые обычно используются в стандартных системах мониторинга. Затея такова, что-бы алгоритм без разметки смог обнаружить проблемы в работе базы.
Сводим задачу к поиску аномалий во временых рядах, где временными рядами являются метрики работы postgres.

## Этапы работ

### 1. Стенд
Поднял виртуалку с PostgreSQL, pg_exporter + отдельную виртуалку для скрейпинга метрик с prometheus.
Залил https://github.com/devrimgunduz/pagila
Почему именно так? 
Нужен стенд для генерации синтетической нагрузки, проблем и сбора метрик, чтобы в последствии сделать из этого 2 датасета. Я решил использовать только постгресовые метрики в датасете, чтобы учиться опеределять проблемы метрикам самой базы, а не сервера на котором она работает.
### 2. Генерация нагрузки
Генерация нагрузки будет с помощью pg_bench. Мы имеем базу проката фильмов, с набором фильмов, актеров, жанров итд.
Я написал несколько SQL запросов которые имитируют действия пользователей: просмотр каталога, поиск конкретного фильма, актера, аренда фильма, платежи итд.
Таким способом мы как бы имитируем нормальную работу базы, те вполне легитимные запросы в нее от бэкенда. Все это время prometheus собирает метрик с нашего pg_exporter.

Теперь о проблемах.
Для генерации проблем я придумал несколько сценариев:
- exclusive lock 
- удаление индекса
- генерация нагрузки на диск с помощью dd
- генерация нагрузки на cpu с помощью sql 
- изменение конфигурации pg, shared_buffer

Заэкспортив метрики из прометеуса я получил датасет содержащий метрики 'нормальной' работы пг и работы с отклонениями.
Я разделил их на два - с проблемами и без.

### 3. Подбор алгоритма 

Поизучав интернет и почитав статьи
https://habr.com/ru/companies/otus/articles/654767/
https://ptresearch.media/articles/kak-nahodit-anomalii-v-trafike-s-pomoshhyu-ml
https://habr.com/ru/articles/671670/
https://habr.com/ru/articles/588320/
https://habr.com/ru/companies/otus/articles/654767/
https://medium.com/data-science/introduction-to-autoencoders-7a47cf4ef14b

Я понял, что хочу использовать AutoEncoder т.к. он позволяет учиться на нормальном поведении без разметки, хорошо работает с многомерными и нелинейными зависимостями, а аномалии определяются через ошибку восстановления.

Приступаем к реализации.

### 4. Реализация

Из датасета решил выделить только важные по моему экспертному мнению метрики (REQUIRED_COLUMNS).
Далее проанализировав датасет я выделил 42 константных признаков которые нам не нужны т.к. они вносят нулевой вклад, что с того что автоенкодер научится их восстанавливать. 

Далее все rate метрики переделал в delta, тк нам всетаки важно детектить аномалию, а при росте rate метрики автоенкодер научится, что это нормально что она растет и может пропустить аномалию

Вид AE:
Input -> Dense(enc) -> Dense(bottleneck) -> Dense(dec) -> Dense(output)

Функции активации в скрытых слоях - ReLU
Функция активации на выходе - Linear
kernel_regularizer - L2(1e-5) (штрафует матрицу весов)
loss - mse

Рання остановка и уменьшение learning_rate при плато

Обучался на датасете без аномалий

### 5. Выводы и результаты

В моем датасете с аномалиями удалось их выявить. На графике с timestamps выбросы строго соответствуют времени запуска проблем. Мне хотелось еще получить график того какая из метрик внесла больше всего в ошибку.
Считаем остатки по каждому признаку

diff = test_recon - X_test_s
per_feat_err = diff ** 2   

Далее считаем распределение вкладов по признакам и получаем картину какая именно метрика потащила аномалию 



